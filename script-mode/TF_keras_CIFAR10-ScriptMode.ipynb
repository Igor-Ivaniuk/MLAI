{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Host a Keras Sequential Model\n",
    "## Using Pipe Mode datasets and distributed training with Horovod\n",
    "This notebook shows how to train and host a Keras Sequential model on SageMaker. The model used for this notebook is a simple deep CNN that was extracted from [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is one of the most popular machine learning datasets. It consists of 60,000 32x32 images belonging to 10 different classes (6,000 images per class). Here are the classes in the dataset, as well as 10 random images from each:\n",
    "\n",
    "![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)\n",
    "\n",
    "In this tutorial, we will train a deep CNN to recognize these images.\n",
    "\n",
    "We'll compare trainig with file mode, pipe mode datasets and distributed training with Horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the CIFAR-10 dataset\n",
    "Downloading the test and training data takes around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords_v1.x.py:34: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Generating data//train/train.tfrecords\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords_v1.x.py:68: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords_v1.x.py:57: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Generating data//validation/validation.tfrecords\n",
      "Generating data//eval/eval.tfrecords\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# import wget # for TF2\n",
    "!python generate_cifar10_tfrecords_v1.x.py --data-dir data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on SageMaker cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-079329190341/data/DEMO-cifar10-tf'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_location = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-cifar10-tf')\n",
    "display(dataset_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring metrics from the job logs\n",
    "SageMaker can get training metrics directly from the logs and send them to CloudWatch metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_metric_definition = [\n",
    "    {'Name': 'train:loss', 'Regex': '.*loss: ([0-9\\\\.]+) - acc: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'train:accuracy', 'Regex': '.*loss: [0-9\\\\.]+ - acc: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:accuracy', 'Regex': '.*step - loss: [0-9\\\\.]+ - acc: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_acc: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:loss', 'Regex': '.*step - loss: [0-9\\\\.]+ - acc: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_acc: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'sec/steps', 'Regex': '.* - \\d+s (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - acc: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_acc: [0-9\\\\.]+'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train image classification based on the cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 10, 'batch-size' : 256}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "source_dir = os.path.join(os.getcwd(), 'source_dir')\n",
    "estimator = TensorFlow(base_job_name='cifar10-tf',\n",
    "                       entry_point='cifar10_keras_main.py',\n",
    "                       source_dir=source_dir,\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       train_instance_count=1, train_instance_type='ml.p3.2xlarge',\n",
    "                       tags = [{'Key' : 'Project', 'Value' : 'cifar10'},{'Key' : 'TensorBoard', 'Value' : 'file'}],\n",
    "                       metric_definitions=keras_metric_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-05 19:24:30 Starting - Starting the training job...\n",
      "2020-05-05 19:24:32 Starting - Launching requested ML instances......\n",
      "2020-05-05 19:25:38 Starting - Preparing the instances for training......\n",
      "2020-05-05 19:26:44 Downloading - Downloading input data...\n",
      "2020-05-05 19:27:26 Training - Training image download completed. Training in progress..\u001b[34m2020-05-05 19:27:29,493 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-05-05 19:27:30,044 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"eval\": \"/opt/ml/input/data/eval\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 256,\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/model\",\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"eval\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-tf-2020-05-05-19-24-30-359\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10_keras_main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10_keras_main.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":256,\"epochs\":10,\"model_dir\":\"s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10_keras_main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"eval\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10_keras_main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":256,\"epochs\":10,\"model_dir\":\"s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-tf-2020-05-05-19-24-30-359\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_keras_main\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10_keras_main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"256\",\"--epochs\",\"10\",\"--model_dir\",\"s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVAL=/opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python cifar10_keras_main.py --batch-size 256 --epochs 10 --model_dir s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34mINFO:root:Writing TensorBoard logs to s3://sagemaker-us-east-1-079329190341/cifar10-tf-2020-05-05-19-24-30-359/model\u001b[0m\n",
      "\u001b[34mINFO:root:Running with MPI=False\u001b[0m\n",
      "\u001b[34mINFO:root:getting data\u001b[0m\n",
      "\u001b[34mINFO:root:Running train in File mode\u001b[0m\n",
      "\u001b[34mINFO:root:Running eval in File mode\u001b[0m\n",
      "\u001b[34mINFO:root:Running validation in File mode\u001b[0m\n",
      "\u001b[34mINFO:root:configuring model\u001b[0m\n",
      "\u001b[34mINFO:root:Starting training\u001b[0m\n",
      "\u001b[34mTrain on 256 samples, validate on 256 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 33:37 - loss: 3.5254 - acc: 0.1367\n",
      "  3/156 [..............................] - ETA: 11:07 - loss: 3.4210 - acc: 0.1055\n",
      "  5/156 [..............................] - ETA: 6:37 - loss: 3.1717 - acc: 0.1281 \n",
      "  7/156 [>.............................] - ETA: 4:41 - loss: 3.0758 - acc: 0.1311\n",
      "  9/156 [>.............................] - ETA: 3:37 - loss: 2.9683 - acc: 0.1389\n",
      " 11/156 [=>............................] - ETA: 2:56 - loss: 2.8804 - acc: 0.1445\n",
      " 13/156 [=>............................] - ETA: 2:28 - loss: 2.7953 - acc: 0.1523\n",
      " 15/156 [=>............................] - ETA: 2:07 - loss: 2.7224 - acc: 0.1583\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 1:51 - loss: 2.6624 - acc: 0.1650\n",
      " 19/156 [==>...........................] - ETA: 1:38 - loss: 2.6116 - acc: 0.1680\n",
      " 21/156 [===>..........................] - ETA: 1:28 - loss: 2.5652 - acc: 0.1745\n",
      " 23/156 [===>..........................] - ETA: 1:19 - loss: 2.5278 - acc: 0.1776\n",
      " 25/156 [===>..........................] - ETA: 1:12 - loss: 2.4929 - acc: 0.1789\n",
      " 27/156 [====>.........................] - ETA: 1:06 - loss: 2.4625 - acc: 0.1823\n",
      " 29/156 [====>.........................] - ETA: 1:01 - loss: 2.4364 - acc: 0.1849\n",
      " 31/156 [====>.........................] - ETA: 56s - loss: 2.4077 - acc: 0.1891 \n",
      " 33/156 [=====>........................] - ETA: 52s - loss: 2.3828 - acc: 0.1941\n",
      " 35/156 [=====>........................] - ETA: 49s - loss: 2.3604 - acc: 0.1973\n",
      " 37/156 [======>.......................] - ETA: 46s - loss: 2.3395 - acc: 0.1997\n",
      " 39/156 [======>.......................] - ETA: 43s - loss: 2.3237 - acc: 0.2023\n",
      " 41/156 [======>.......................] - ETA: 40s - loss: 2.3061 - acc: 0.2044\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 38s - loss: 2.2903 - acc: 0.2075\n",
      " 45/156 [=======>......................] - ETA: 36s - loss: 2.2751 - acc: 0.2086\n",
      " 47/156 [========>.....................] - ETA: 34s - loss: 2.2625 - acc: 0.2112\n",
      " 49/156 [========>.....................] - ETA: 32s - loss: 2.2482 - acc: 0.2139\n",
      " 51/156 [========>.....................] - ETA: 30s - loss: 2.2356 - acc: 0.2159\n",
      " 53/156 [=========>....................] - ETA: 29s - loss: 2.2247 - acc: 0.2182\n",
      " 55/156 [=========>....................] - ETA: 27s - loss: 2.2129 - acc: 0.2200\n",
      " 57/156 [=========>....................] - ETA: 26s - loss: 2.2017 - acc: 0.2219\n",
      " 59/156 [==========>...................] - ETA: 25s - loss: 2.1897 - acc: 0.2238\n",
      " 61/156 [==========>...................] - ETA: 23s - loss: 2.1785 - acc: 0.2261\n",
      " 63/156 [===========>..................] - ETA: 22s - loss: 2.1677 - acc: 0.2288\n",
      " 65/156 [===========>..................] - ETA: 21s - loss: 2.1630 - acc: 0.2285\n",
      " 67/156 [===========>..................] - ETA: 20s - loss: 2.1540 - acc: 0.2308\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 19s - loss: 2.1461 - acc: 0.2327\n",
      " 71/156 [============>.................] - ETA: 18s - loss: 2.1367 - acc: 0.2345\n",
      " 73/156 [=============>................] - ETA: 17s - loss: 2.1278 - acc: 0.2366\n",
      " 75/156 [=============>................] - ETA: 17s - loss: 2.1200 - acc: 0.2382\n",
      " 77/156 [=============>................] - ETA: 16s - loss: 2.1131 - acc: 0.2403\n",
      " 79/156 [==============>...............] - ETA: 15s - loss: 2.1072 - acc: 0.2421\n",
      " 81/156 [==============>...............] - ETA: 14s - loss: 2.0995 - acc: 0.2437\n",
      " 82/156 [==============>...............] - ETA: 14s - loss: 2.0964 - acc: 0.2446\n",
      " 84/156 [===============>..............] - ETA: 13s - loss: 2.0884 - acc: 0.2469\n",
      " 86/156 [===============>..............] - ETA: 13s - loss: 2.0801 - acc: 0.2489\n",
      " 88/156 [===============>..............] - ETA: 12s - loss: 2.0733 - acc: 0.2508\n",
      " 90/156 [================>.............] - ETA: 12s - loss: 2.0652 - acc: 0.2530\n",
      " 92/156 [================>.............] - ETA: 11s - loss: 2.0599 - acc: 0.2540\n",
      " 94/156 [=================>............] - ETA: 10s - loss: 2.0548 - acc: 0.2554\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 10s - loss: 2.0491 - acc: 0.2572\n",
      " 98/156 [=================>............] - ETA: 9s - loss: 2.0436 - acc: 0.2586 \u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 9s - loss: 2.0376 - acc: 0.2600\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 8s - loss: 2.0325 - acc: 0.2612\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 8s - loss: 2.0272 - acc: 0.2631\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 8s - loss: 2.0208 - acc: 0.2651\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 7s - loss: 2.0164 - acc: 0.2663\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 7s - loss: 2.0115 - acc: 0.2672\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 6s - loss: 2.0061 - acc: 0.2691\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 6s - loss: 2.0006 - acc: 0.2710\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 5s - loss: 1.9955 - acc: 0.2724\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 5s - loss: 1.9908 - acc: 0.2736\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 5s - loss: 1.9866 - acc: 0.2750\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 4s - loss: 1.9806 - acc: 0.2763\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 4s - loss: 1.9771 - acc: 0.2778\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 4s - loss: 1.9721 - acc: 0.2791\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 3s - loss: 1.9680 - acc: 0.2795\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 3s - loss: 1.9643 - acc: 0.2804\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 3s - loss: 1.9597 - acc: 0.2814\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 2s - loss: 1.9565 - acc: 0.2820\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 2s - loss: 1.9524 - acc: 0.2831\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 2s - loss: 1.9496 - acc: 0.2842\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 2s - loss: 1.9459 - acc: 0.2856\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 1s - loss: 1.9430 - acc: 0.2869\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 1s - loss: 1.9403 - acc: 0.2875\u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 1s - loss: 1.9357 - acc: 0.2887\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 1s - loss: 1.9322 - acc: 0.2899\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 0s - loss: 1.9281 - acc: 0.2912\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 0s - loss: 1.9242 - acc: 0.2925\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 0s - loss: 1.9207 - acc: 0.2938\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 20s 129ms/step - loss: 1.9169 - acc: 0.2950 - val_loss: 2.0458 - val_acc: 0.2679\u001b[0m\n",
      "\u001b[34mEpoch 2/10\n",
      "\n",
      "  1/156 [..............................] - ETA: 6s - loss: 1.6916 - acc: 0.3516\n",
      "  3/156 [..............................] - ETA: 5s - loss: 1.6519 - acc: 0.3672\n",
      "  5/156 [..............................] - ETA: 5s - loss: 1.6201 - acc: 0.3883\n",
      "  7/156 [>.............................] - ETA: 5s - loss: 1.6256 - acc: 0.3912\n",
      "  9/156 [>.............................] - ETA: 5s - loss: 1.6209 - acc: 0.3885\n",
      " 11/156 [=>............................] - ETA: 5s - loss: 1.6286 - acc: 0.3906\n",
      " 13/156 [=>............................] - ETA: 5s - loss: 1.6258 - acc: 0.3909\n",
      " 15/156 [=>............................] - ETA: 5s - loss: 1.6365 - acc: 0.3867\n",
      " 17/156 [==>...........................] - ETA: 5s - loss: 1.6349 - acc: 0.3860\n",
      " 19/156 [==>...........................] - ETA: 5s - loss: 1.6330 - acc: 0.3857\n",
      " 21/156 [===>..........................] - ETA: 4s - loss: 1.6359 - acc: 0.3847\n",
      " 23/156 [===>..........................] - ETA: 4s - loss: 1.6339 - acc: 0.3891\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 4s - loss: 1.6309 - acc: 0.3891\n",
      " 27/156 [====>.........................] - ETA: 4s - loss: 1.6282 - acc: 0.3915\n",
      " 29/156 [====>.........................] - ETA: 4s - loss: 1.6262 - acc: 0.3928\n",
      " 31/156 [====>.........................] - ETA: 4s - loss: 1.6229 - acc: 0.3949\n",
      " 33/156 [=====>........................] - ETA: 4s - loss: 1.6201 - acc: 0.3965\n",
      " 35/156 [=====>........................] - ETA: 4s - loss: 1.6157 - acc: 0.3985\n",
      " 37/156 [======>.......................] - ETA: 4s - loss: 1.6141 - acc: 0.3966\n",
      " 39/156 [======>.......................] - ETA: 4s - loss: 1.6115 - acc: 0.3972\n",
      " 41/156 [======>.......................] - ETA: 4s - loss: 1.6094 - acc: 0.3976\n",
      " 43/156 [=======>......................] - ETA: 4s - loss: 1.6084 - acc: 0.3997\n",
      " 45/156 [=======>......................] - ETA: 4s - loss: 1.6090 - acc: 0.4001\n",
      " 47/156 [========>.....................] - ETA: 3s - loss: 1.6088 - acc: 0.3993\n",
      " 49/156 [========>.....................] - ETA: 3s - loss: 1.6058 - acc: 0.4010\n",
      " 51/156 [========>.....................] - ETA: 3s - loss: 1.5990 - acc: 0.4031\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 3s - loss: 1.5957 - acc: 0.4039\n",
      " 55/156 [=========>....................] - ETA: 3s - loss: 1.5914 - acc: 0.4055\n",
      " 57/156 [=========>....................] - ETA: 3s - loss: 1.5914 - acc: 0.4059\n",
      " 59/156 [==========>...................] - ETA: 3s - loss: 1.5891 - acc: 0.4068\n",
      " 61/156 [==========>...................] - ETA: 3s - loss: 1.5873 - acc: 0.4073\n",
      " 63/156 [===========>..................] - ETA: 3s - loss: 1.5864 - acc: 0.4067\n",
      " 65/156 [===========>..................] - ETA: 3s - loss: 1.5842 - acc: 0.4081\n",
      " 67/156 [===========>..................] - ETA: 3s - loss: 1.5822 - acc: 0.4089\n",
      " 69/156 [============>.................] - ETA: 3s - loss: 1.5826 - acc: 0.4085\n",
      " 71/156 [============>.................] - ETA: 3s - loss: 1.5823 - acc: 0.4093\n",
      " 73/156 [=============>................] - ETA: 3s - loss: 1.5793 - acc: 0.4105\n",
      " 75/156 [=============>................] - ETA: 2s - loss: 1.5782 - acc: 0.4110\n",
      " 77/156 [=============>................] - ETA: 2s - loss: 1.5772 - acc: 0.4119\n",
      " 79/156 [==============>...............] - ETA: 2s - loss: 1.5759 - acc: 0.4129\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 2s - loss: 1.5736 - acc: 0.4135\n",
      " 83/156 [==============>...............] - ETA: 2s - loss: 1.5707 - acc: 0.4143\n",
      " 85/156 [===============>..............] - ETA: 2s - loss: 1.5684 - acc: 0.4155\n",
      " 87/156 [===============>..............] - ETA: 2s - loss: 1.5680 - acc: 0.4159\n",
      " 89/156 [================>.............] - ETA: 2s - loss: 1.5674 - acc: 0.4164\n",
      " 91/156 [================>.............] - ETA: 2s - loss: 1.5663 - acc: 0.4163\n",
      " 93/156 [================>.............] - ETA: 2s - loss: 1.5656 - acc: 0.4164\n",
      " 95/156 [=================>............] - ETA: 2s - loss: 1.5651 - acc: 0.4168\n",
      " 97/156 [=================>............] - ETA: 2s - loss: 1.5643 - acc: 0.4169\n",
      " 99/156 [==================>...........] - ETA: 2s - loss: 1.5620 - acc: 0.4177\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 2s - loss: 1.5607 - acc: 0.4189\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 1s - loss: 1.5589 - acc: 0.4194\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 1s - loss: 1.5568 - acc: 0.4205\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 1s - loss: 1.5546 - acc: 0.4212\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 1s - loss: 1.5541 - acc: 0.4210\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 1s - loss: 1.5539 - acc: 0.4212\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 1s - loss: 1.5513 - acc: 0.4227\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 1s - loss: 1.5498 - acc: 0.4236\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 1s - loss: 1.5497 - acc: 0.4238\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 1s - loss: 1.5483 - acc: 0.4243\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 1s - loss: 1.5458 - acc: 0.4252\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 1s - loss: 1.5455 - acc: 0.4254\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 1s - loss: 1.5450 - acc: 0.4257\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 1s - loss: 1.5437 - acc: 0.4260\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 0s - loss: 1.5430 - acc: 0.4267\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 0s - loss: 1.5423 - acc: 0.4269\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 0s - loss: 1.5397 - acc: 0.4280\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 0s - loss: 1.5383 - acc: 0.4286\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 0s - loss: 1.5373 - acc: 0.4286\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 0s - loss: 1.5361 - acc: 0.4295\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 0s - loss: 1.5347 - acc: 0.4301\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 0s - loss: 1.5333 - acc: 0.4308\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 0s - loss: 1.5311 - acc: 0.4315\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 0s - loss: 1.5301 - acc: 0.4321\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 0s - loss: 1.5289 - acc: 0.4325\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 0s - loss: 1.5276 - acc: 0.4332\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 0s - loss: 1.5265 - acc: 0.4339\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 1.5252 - acc: 0.4345\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 7s 44ms/step - loss: 1.5246 - acc: 0.4351 - val_loss: 1.4782 - val_acc: 0.4732\u001b[0m\n",
      "\u001b[34mEpoch 3/10\n",
      "\n",
      "  1/156 [..............................] - ETA: 5s - loss: 1.3407 - acc: 0.4766\n",
      "  3/156 [..............................] - ETA: 5s - loss: 1.3508 - acc: 0.4792\n",
      "  5/156 [..............................] - ETA: 5s - loss: 1.3474 - acc: 0.4867\n",
      "  7/156 [>.............................] - ETA: 5s - loss: 1.3849 - acc: 0.4760\n",
      "  9/156 [>.............................] - ETA: 5s - loss: 1.3908 - acc: 0.4831\n",
      " 11/156 [=>............................] - ETA: 5s - loss: 1.3974 - acc: 0.4862\n",
      " 13/156 [=>............................] - ETA: 5s - loss: 1.3925 - acc: 0.4916\n",
      " 15/156 [=>............................] - ETA: 5s - loss: 1.3872 - acc: 0.4922\n",
      " 17/156 [==>...........................] - ETA: 5s - loss: 1.3863 - acc: 0.4917\n",
      " 19/156 [==>...........................] - ETA: 5s - loss: 1.3812 - acc: 0.4942\n",
      " 21/156 [===>..........................] - ETA: 4s - loss: 1.3846 - acc: 0.4916\n",
      " 23/156 [===>..........................] - ETA: 4s - loss: 1.3843 - acc: 0.4929\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 4s - loss: 1.3844 - acc: 0.4917\n",
      " 27/156 [====>.........................] - ETA: 4s - loss: 1.3968 - acc: 0.4887\n",
      " 29/156 [====>.........................] - ETA: 4s - loss: 1.3947 - acc: 0.4894\n",
      " 31/156 [====>.........................] - ETA: 4s - loss: 1.3892 - acc: 0.4924\n",
      " 33/156 [=====>........................] - ETA: 4s - loss: 1.3902 - acc: 0.4938\n",
      " 35/156 [=====>........................] - ETA: 4s - loss: 1.3852 - acc: 0.4944\n",
      " 37/156 [======>.......................] - ETA: 4s - loss: 1.3866 - acc: 0.4938\n",
      " 39/156 [======>.......................] - ETA: 4s - loss: 1.3821 - acc: 0.4960\n",
      " 41/156 [======>.......................] - ETA: 4s - loss: 1.3794 - acc: 0.4970\n",
      " 43/156 [=======>......................] - ETA: 4s - loss: 1.3758 - acc: 0.4987\n",
      " 45/156 [=======>......................] - ETA: 4s - loss: 1.3713 - acc: 0.4999\n",
      " 47/156 [========>.....................] - ETA: 3s - loss: 1.3686 - acc: 0.5012\n",
      " 49/156 [========>.....................] - ETA: 3s - loss: 1.3685 - acc: 0.5020\n",
      " 51/156 [========>.....................] - ETA: 3s - loss: 1.3695 - acc: 0.5015\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 3s - loss: 1.3668 - acc: 0.5033\n",
      " 55/156 [=========>....................] - ETA: 3s - loss: 1.3658 - acc: 0.5034\n",
      " 57/156 [=========>....................] - ETA: 3s - loss: 1.3652 - acc: 0.5030\n",
      " 59/156 [==========>...................] - ETA: 3s - loss: 1.3677 - acc: 0.5024\n",
      " 61/156 [==========>...................] - ETA: 3s - loss: 1.3670 - acc: 0.5027\n",
      " 63/156 [===========>..................] - ETA: 3s - loss: 1.3662 - acc: 0.5027\n",
      " 65/156 [===========>..................] - ETA: 3s - loss: 1.3665 - acc: 0.5021\n",
      " 67/156 [===========>..................] - ETA: 3s - loss: 1.3691 - acc: 0.5020\n",
      " 69/156 [============>.................] - ETA: 3s - loss: 1.3681 - acc: 0.5024\n",
      " 71/156 [============>.................] - ETA: 3s - loss: 1.3658 - acc: 0.5039\n",
      " 73/156 [=============>................] - ETA: 3s - loss: 1.3652 - acc: 0.5041\n",
      " 75/156 [=============>................] - ETA: 2s - loss: 1.3616 - acc: 0.5056\n",
      " 77/156 [=============>................] - ETA: 2s - loss: 1.3613 - acc: 0.5064\n",
      " 79/156 [==============>...............] - ETA: 2s - loss: 1.3603 - acc: 0.5074\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 2s - loss: 1.3561 - acc: 0.5083\n",
      " 83/156 [==============>...............] - ETA: 2s - loss: 1.3552 - acc: 0.5095\n",
      " 85/156 [===============>..............] - ETA: 2s - loss: 1.3537 - acc: 0.5105\n",
      " 87/156 [===============>..............] - ETA: 2s - loss: 1.3549 - acc: 0.5106\n",
      " 89/156 [================>.............] - ETA: 2s - loss: 1.3539 - acc: 0.5106\n",
      " 91/156 [================>.............] - ETA: 2s - loss: 1.3523 - acc: 0.5115\n",
      " 93/156 [================>.............] - ETA: 2s - loss: 1.3506 - acc: 0.5118\n",
      " 95/156 [=================>............] - ETA: 2s - loss: 1.3495 - acc: 0.5123\n",
      " 97/156 [=================>............] - ETA: 2s - loss: 1.3491 - acc: 0.5124\n",
      " 99/156 [==================>...........] - ETA: 2s - loss: 1.3492 - acc: 0.5122\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 2s - loss: 1.3488 - acc: 0.5123\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 1s - loss: 1.3479 - acc: 0.5126\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 1s - loss: 1.3476 - acc: 0.5132\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 1s - loss: 1.3475 - acc: 0.5129\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 1s - loss: 1.3467 - acc: 0.5131\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 1s - loss: 1.3474 - acc: 0.5124\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 1s - loss: 1.3456 - acc: 0.5131\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 1s - loss: 1.3446 - acc: 0.5135\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 1s - loss: 1.3436 - acc: 0.5137\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 1s - loss: 1.3441 - acc: 0.5131\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 1s - loss: 1.3436 - acc: 0.5135\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 1s - loss: 1.3426 - acc: 0.5141\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 1s - loss: 1.3415 - acc: 0.5144\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 1s - loss: 1.3393 - acc: 0.5149\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 0s - loss: 1.3385 - acc: 0.5152\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 0s - loss: 1.3383 - acc: 0.5154\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 0s - loss: 1.3363 - acc: 0.5157\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 0s - loss: 1.3358 - acc: 0.5160\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 0s - loss: 1.3346 - acc: 0.5164\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 0s - loss: 1.3327 - acc: 0.5171\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 0s - loss: 1.3318 - acc: 0.5176\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 0s - loss: 1.3304 - acc: 0.5177\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 0s - loss: 1.3294 - acc: 0.5183\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 0s - loss: 1.3288 - acc: 0.5187\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 0s - loss: 1.3290 - acc: 0.5187\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 0s - loss: 1.3279 - acc: 0.5193\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 0s - loss: 1.3276 - acc: 0.5194\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 1.3268 - acc: 0.5197\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 7s 44ms/step - loss: 1.3261 - acc: 0.5199 - val_loss: 1.3613 - val_acc: 0.4947\u001b[0m\n",
      "\u001b[34mEpoch 4/10\n",
      "\n",
      "  1/156 [..............................] - ETA: 5s - loss: 1.2888 - acc: 0.5078\n",
      "  3/156 [..............................] - ETA: 5s - loss: 1.2701 - acc: 0.5404\n",
      "  5/156 [..............................] - ETA: 5s - loss: 1.2334 - acc: 0.5523\n",
      "  7/156 [>.............................] - ETA: 5s - loss: 1.2420 - acc: 0.5458\n",
      "  9/156 [>.............................] - ETA: 5s - loss: 1.2505 - acc: 0.5451\n",
      " 11/156 [=>............................] - ETA: 5s - loss: 1.2450 - acc: 0.5451\n",
      " 13/156 [=>............................] - ETA: 5s - loss: 1.2441 - acc: 0.5475\n",
      " 15/156 [=>............................] - ETA: 5s - loss: 1.2460 - acc: 0.5482\n",
      " 17/156 [==>...........................] - ETA: 5s - loss: 1.2447 - acc: 0.5480\n",
      " 19/156 [==>...........................] - ETA: 5s - loss: 1.2364 - acc: 0.5506\n",
      " 21/156 [===>..........................] - ETA: 5s - loss: 1.2436 - acc: 0.5482\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 4s - loss: 1.2471 - acc: 0.5467\n",
      " 25/156 [===>..........................] - ETA: 4s - loss: 1.2423 - acc: 0.5478\n",
      " 27/156 [====>.........................] - ETA: 4s - loss: 1.2365 - acc: 0.5521\n",
      " 29/156 [====>.........................] - ETA: 4s - loss: 1.2418 - acc: 0.5535\n",
      " 31/156 [====>.........................] - ETA: 4s - loss: 1.2424 - acc: 0.5515\n",
      " 33/156 [=====>........................] - ETA: 4s - loss: 1.2410 - acc: 0.5531\n",
      " 35/156 [=====>........................] - ETA: 4s - loss: 1.2383 - acc: 0.5542\n",
      " 37/156 [======>.......................] - ETA: 4s - loss: 1.2381 - acc: 0.5536\n",
      " 39/156 [======>.......................] - ETA: 4s - loss: 1.2357 - acc: 0.5539\n",
      " 41/156 [======>.......................] - ETA: 4s - loss: 1.2288 - acc: 0.5570\n",
      " 43/156 [=======>......................] - ETA: 4s - loss: 1.2299 - acc: 0.5576\n",
      " 45/156 [=======>......................] - ETA: 4s - loss: 1.2337 - acc: 0.5555\n",
      " 47/156 [========>.....................] - ETA: 4s - loss: 1.2327 - acc: 0.5565\n",
      " 49/156 [========>.....................] - ETA: 3s - loss: 1.2312 - acc: 0.5567\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 3s - loss: 1.2300 - acc: 0.5577\n",
      " 53/156 [=========>....................] - ETA: 3s - loss: 1.2276 - acc: 0.5583\n",
      " 55/156 [=========>....................] - ETA: 3s - loss: 1.2261 - acc: 0.5582\n",
      " 57/156 [=========>....................] - ETA: 3s - loss: 1.2251 - acc: 0.5584\n",
      " 59/156 [==========>...................] - ETA: 3s - loss: 1.2227 - acc: 0.5597\n",
      " 61/156 [==========>...................] - ETA: 3s - loss: 1.2233 - acc: 0.5590\n",
      " 63/156 [===========>..................] - ETA: 3s - loss: 1.2215 - acc: 0.5596\n",
      " 65/156 [===========>..................] - ETA: 3s - loss: 1.2212 - acc: 0.5592\n",
      " 67/156 [===========>..................] - ETA: 3s - loss: 1.2216 - acc: 0.5596\n",
      " 69/156 [============>.................] - ETA: 3s - loss: 1.2221 - acc: 0.5591\n",
      " 71/156 [============>.................] - ETA: 3s - loss: 1.2200 - acc: 0.5604\n",
      " 73/156 [=============>................] - ETA: 3s - loss: 1.2185 - acc: 0.5605\n",
      " 75/156 [=============>................] - ETA: 2s - loss: 1.2178 - acc: 0.5605\n",
      " 77/156 [=============>................] - ETA: 2s - loss: 1.2165 - acc: 0.5613\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 2s - loss: 1.2152 - acc: 0.5617\n",
      " 81/156 [==============>...............] - ETA: 2s - loss: 1.2145 - acc: 0.5619\n",
      " 83/156 [==============>...............] - ETA: 2s - loss: 1.2155 - acc: 0.5617\n",
      " 85/156 [===============>..............] - ETA: 2s - loss: 1.2153 - acc: 0.5619\n",
      " 87/156 [===============>..............] - ETA: 2s - loss: 1.2169 - acc: 0.5608\n",
      " 89/156 [================>.............] - ETA: 2s - loss: 1.2163 - acc: 0.5614\n",
      " 91/156 [================>.............] - ETA: 2s - loss: 1.2172 - acc: 0.5616\n",
      " 93/156 [================>.............] - ETA: 2s - loss: 1.2164 - acc: 0.5617\n",
      " 95/156 [=================>............] - ETA: 2s - loss: 1.2163 - acc: 0.5624\n",
      " 97/156 [=================>............] - ETA: 2s - loss: 1.2149 - acc: 0.5627\n",
      " 99/156 [==================>...........] - ETA: 2s - loss: 1.2134 - acc: 0.5631\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 2s - loss: 1.2121 - acc: 0.5635\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 1s - loss: 1.2118 - acc: 0.5638\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 1s - loss: 1.2085 - acc: 0.5645\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 1s - loss: 1.2076 - acc: 0.5645\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 1s - loss: 1.2063 - acc: 0.5651\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 1s - loss: 1.2058 - acc: 0.5652\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 1s - loss: 1.2045 - acc: 0.5657\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 1s - loss: 1.2037 - acc: 0.5658\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 1s - loss: 1.2033 - acc: 0.5663\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 1s - loss: 1.2031 - acc: 0.5666\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 1s - loss: 1.2037 - acc: 0.5662\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 1s - loss: 1.2029 - acc: 0.5667\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 1s - loss: 1.2026 - acc: 0.5667\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 1s - loss: 1.2019 - acc: 0.5664\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 0s - loss: 1.2018 - acc: 0.5666\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 0s - loss: 1.2006 - acc: 0.5673\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 0s - loss: 1.1990 - acc: 0.5679\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 0s - loss: 1.1981 - acc: 0.5684\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 0s - loss: 1.1976 - acc: 0.5685\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 0s - loss: 1.1975 - acc: 0.5683\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 0s - loss: 1.1968 - acc: 0.5682\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 0s - loss: 1.1976 - acc: 0.5679\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 0s - loss: 1.1963 - acc: 0.5685\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 0s - loss: 1.1969 - acc: 0.5685\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 0s - loss: 1.1958 - acc: 0.5689\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 0s - loss: 1.1950 - acc: 0.5692\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 0s - loss: 1.1947 - acc: 0.5691\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 1.1935 - acc: 0.5696\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 7s 43ms/step - loss: 1.1936 - acc: 0.5696 - val_loss: 1.3641 - val_acc: 0.5211\u001b[0m\n",
      "\u001b[34mEpoch 5/10\n",
      "\n",
      "  1/156 [..............................] - ETA: 5s - loss: 1.0417 - acc: 0.6250\n",
      "  3/156 [..............................] - ETA: 5s - loss: 1.1912 - acc: 0.5846\n",
      "  5/156 [..............................] - ETA: 5s - loss: 1.1913 - acc: 0.5820\n",
      "  7/156 [>.............................] - ETA: 5s - loss: 1.1884 - acc: 0.5798\n",
      "  9/156 [>.............................] - ETA: 5s - loss: 1.1702 - acc: 0.5786\n",
      " 11/156 [=>............................] - ETA: 5s - loss: 1.1720 - acc: 0.5742\n",
      " 13/156 [=>............................] - ETA: 5s - loss: 1.1659 - acc: 0.5790\n",
      " 15/156 [=>............................] - ETA: 5s - loss: 1.1518 - acc: 0.5833\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 5s - loss: 1.1390 - acc: 0.5857\n",
      " 19/156 [==>...........................] - ETA: 4s - loss: 1.1366 - acc: 0.5874\n",
      " 21/156 [===>..........................] - ETA: 4s - loss: 1.1460 - acc: 0.5833\n",
      " 23/156 [===>..........................] - ETA: 4s - loss: 1.1404 - acc: 0.5861\n",
      " 25/156 [===>..........................] - ETA: 4s - loss: 1.1382 - acc: 0.5867\n",
      " 27/156 [====>.........................] - ETA: 4s - loss: 1.1311 - acc: 0.5870\n",
      " 29/156 [====>.........................] - ETA: 4s - loss: 1.1338 - acc: 0.5869\n",
      " 31/156 [====>.........................] - ETA: 4s - loss: 1.1378 - acc: 0.5862\n",
      " 33/156 [=====>........................] - ETA: 4s - loss: 1.1352 - acc: 0.5883\n",
      " 35/156 [=====>........................] - ETA: 4s - loss: 1.1382 - acc: 0.5867\n",
      " 37/156 [======>.......................] - ETA: 4s - loss: 1.1356 - acc: 0.5880\n",
      " 39/156 [======>.......................] - ETA: 4s - loss: 1.1369 - acc: 0.5878\n",
      " 41/156 [======>.......................] - ETA: 4s - loss: 1.1359 - acc: 0.5881\n",
      " 43/156 [=======>......................] - ETA: 4s - loss: 1.1346 - acc: 0.5892\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 4s - loss: 1.1338 - acc: 0.5899\n",
      " 47/156 [========>.....................] - ETA: 3s - loss: 1.1342 - acc: 0.5894\n",
      " 49/156 [========>.....................] - ETA: 3s - loss: 1.1346 - acc: 0.5883\n",
      " 51/156 [========>.....................] - ETA: 3s - loss: 1.1339 - acc: 0.5889\n",
      " 53/156 [=========>....................] - ETA: 3s - loss: 1.1330 - acc: 0.5901\n",
      " 55/156 [=========>....................] - ETA: 3s - loss: 1.1359 - acc: 0.5898\n",
      " 57/156 [=========>....................] - ETA: 3s - loss: 1.1336 - acc: 0.5907\n",
      " 59/156 [==========>...................] - ETA: 3s - loss: 1.1346 - acc: 0.5905\n",
      " 61/156 [==========>...................] - ETA: 3s - loss: 1.1314 - acc: 0.5909\n",
      " 63/156 [===========>..................] - ETA: 3s - loss: 1.1280 - acc: 0.5924\n",
      " 65/156 [===========>..................] - ETA: 3s - loss: 1.1286 - acc: 0.5925\n",
      " 67/156 [===========>..................] - ETA: 3s - loss: 1.1275 - acc: 0.5931\n",
      " 69/156 [============>.................] - ETA: 3s - loss: 1.1284 - acc: 0.5934\n",
      " 71/156 [============>.................] - ETA: 3s - loss: 1.1287 - acc: 0.5932\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 3s - loss: 1.1267 - acc: 0.5942\n",
      " 75/156 [=============>................] - ETA: 2s - loss: 1.1293 - acc: 0.5942\n",
      " 77/156 [=============>................] - ETA: 2s - loss: 1.1299 - acc: 0.5936\n",
      " 79/156 [==============>...............] - ETA: 2s - loss: 1.1315 - acc: 0.5936\n",
      " 81/156 [==============>...............] - ETA: 2s - loss: 1.1298 - acc: 0.5933\n",
      " 83/156 [==============>...............] - ETA: 2s - loss: 1.1303 - acc: 0.5925\n",
      " 85/156 [===============>..............] - ETA: 2s - loss: 1.1308 - acc: 0.5925\n",
      " 87/156 [===============>..............] - ETA: 2s - loss: 1.1303 - acc: 0.5931\n",
      " 89/156 [================>.............] - ETA: 2s - loss: 1.1292 - acc: 0.5933\n",
      " 91/156 [================>.............] - ETA: 2s - loss: 1.1273 - acc: 0.5941\n",
      " 93/156 [================>.............] - ETA: 2s - loss: 1.1275 - acc: 0.5947\n",
      " 95/156 [=================>............] - ETA: 2s - loss: 1.1281 - acc: 0.5952\n",
      " 97/156 [=================>............] - ETA: 2s - loss: 1.1292 - acc: 0.5956\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 2s - loss: 1.1286 - acc: 0.5954\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 1s - loss: 1.1282 - acc: 0.5957\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 1s - loss: 1.1285 - acc: 0.5957\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 1s - loss: 1.1293 - acc: 0.5955\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 1s - loss: 1.1304 - acc: 0.5954\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 1s - loss: 1.1279 - acc: 0.5969\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 1s - loss: 1.1272 - acc: 0.5971\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 1s - loss: 1.1265 - acc: 0.5974\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 1s - loss: 1.1259 - acc: 0.5979\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 1s - loss: 1.1253 - acc: 0.5979\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 1s - loss: 1.1246 - acc: 0.5981\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 1s - loss: 1.1245 - acc: 0.5980\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 1s - loss: 1.1231 - acc: 0.5985\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 1s - loss: 1.1229 - acc: 0.5989\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 1s - loss: 1.1216 - acc: 0.5995\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 0s - loss: 1.1216 - acc: 0.5991\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 0s - loss: 1.1206 - acc: 0.5991\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 0s - loss: 1.1202 - acc: 0.5994\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 0s - loss: 1.1186 - acc: 0.6003\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 0s - loss: 1.1189 - acc: 0.6004\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 0s - loss: 1.1174 - acc: 0.6011\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 0s - loss: 1.1185 - acc: 0.6009\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 0s - loss: 1.1177 - acc: 0.6014\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 0s - loss: 1.1163 - acc: 0.6016\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 0s - loss: 1.1158 - acc: 0.6019\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 0s - loss: 1.1146 - acc: 0.6025\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 0s - loss: 1.1136 - acc: 0.6030\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 0s - loss: 1.1130 - acc: 0.6032\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 1.1117 - acc: 0.6038\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 7s 43ms/step - loss: 1.1119 - acc: 0.6037 - val_loss: 1.1355 - val_acc: 0.5878\u001b[0m\n",
      "\u001b[34mEpoch 6/10\n",
      "\n",
      "  1/156 [..............................] - ETA: 6s - loss: 1.2231 - acc: 0.5703\n",
      "  3/156 [..............................] - ETA: 5s - loss: 1.1177 - acc: 0.6107\n",
      "  5/156 [..............................] - ETA: 5s - loss: 1.1293 - acc: 0.6047\n",
      "  7/156 [>.............................] - ETA: 5s - loss: 1.1055 - acc: 0.6144\n",
      "  9/156 [>.............................] - ETA: 5s - loss: 1.0923 - acc: 0.6163\n",
      " 11/156 [=>............................] - ETA: 5s - loss: 1.0911 - acc: 0.6115\n",
      " 13/156 [=>............................] - ETA: 5s - loss: 1.0830 - acc: 0.6151\n",
      " 15/156 [=>............................] - ETA: 5s - loss: 1.0747 - acc: 0.6190\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 5s - loss: 1.0726 - acc: 0.6195\n",
      " 19/156 [==>...........................] - ETA: 5s - loss: 1.0816 - acc: 0.6172\n",
      " 21/156 [===>..........................] - ETA: 4s - loss: 1.0851 - acc: 0.6148\n",
      " 23/156 [===>..........................] - ETA: 4s - loss: 1.0743 - acc: 0.6167\n",
      " 25/156 [===>..........................] - ETA: 4s - loss: 1.0760 - acc: 0.6169\n",
      " 27/156 [====>.........................] - ETA: 4s - loss: 1.0782 - acc: 0.6160\n",
      " 29/156 [====>.........................] - ETA: 4s - loss: 1.0735 - acc: 0.6185\n",
      " 31/156 [====>.........................] - ETA: 4s - loss: 1.0760 - acc: 0.6187\n",
      " 33/156 [=====>........................] - ETA: 4s - loss: 1.0800 - acc: 0.6170\n",
      " 35/156 [=====>........................] - ETA: 4s - loss: 1.0809 - acc: 0.6171\n",
      " 37/156 [======>.......................] - ETA: 4s - loss: 1.0784 - acc: 0.6186\n",
      " 39/156 [======>.......................] - ETA: 4s - loss: 1.0755 - acc: 0.6208\n",
      " 41/156 [======>.......................] - ETA: 4s - loss: 1.0746 - acc: 0.6210\n",
      " 43/156 [=======>......................] - ETA: 4s - loss: 1.0736 - acc: 0.6215\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 4s - loss: 1.0714 - acc: 0.6213\n",
      " 47/156 [========>.....................] - ETA: 3s - loss: 1.0694 - acc: 0.6218\n",
      " 49/156 [========>.....................] - ETA: 3s - loss: 1.0693 - acc: 0.6209\n",
      " 51/156 [========>.....................] - ETA: 3s - loss: 1.0709 - acc: 0.6201\n",
      " 53/156 [=========>....................] - ETA: 3s - loss: 1.0698 - acc: 0.6205\n",
      " 55/156 [=========>....................] - ETA: 3s - loss: 1.0731 - acc: 0.6197\n",
      " 57/156 [=========>....................] - ETA: 3s - loss: 1.0716 - acc: 0.6196\n",
      " 59/156 [==========>...................] - ETA: 3s - loss: 1.0695 - acc: 0.6202\n",
      " 61/156 [==========>...................] - ETA: 3s - loss: 1.0687 - acc: 0.6199\n",
      " 63/156 [===========>..................] - ETA: 3s - loss: 1.0680 - acc: 0.6202\n",
      " 65/156 [===========>..................] - ETA: 3s - loss: 1.0670 - acc: 0.6207\n",
      " 67/156 [===========>..................] - ETA: 3s - loss: 1.0691 - acc: 0.6200\n",
      " 69/156 [============>.................] - ETA: 3s - loss: 1.0661 - acc: 0.6205\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 3s - loss: 1.0661 - acc: 0.6202\n",
      " 73/156 [=============>................] - ETA: 3s - loss: 1.0675 - acc: 0.6199\n",
      " 75/156 [=============>................] - ETA: 2s - loss: 1.0677 - acc: 0.6195\n",
      " 77/156 [=============>................] - ETA: 2s - loss: 1.0667 - acc: 0.6197\n",
      " 79/156 [==============>...............] - ETA: 2s - loss: 1.0644 - acc: 0.6210\n",
      " 81/156 [==============>...............] - ETA: 2s - loss: 1.0636 - acc: 0.6212\n",
      " 83/156 [==============>...............] - ETA: 2s - loss: 1.0622 - acc: 0.6213\n",
      " 85/156 [===============>..............] - ETA: 2s - loss: 1.0611 - acc: 0.6211\n",
      " 87/156 [===============>..............] - ETA: 2s - loss: 1.0601 - acc: 0.6213\n",
      " 89/156 [================>.............] - ETA: 2s - loss: 1.0591 - acc: 0.6220\n",
      " 91/156 [================>.............] - ETA: 2s - loss: 1.0565 - acc: 0.6227\n",
      " 93/156 [================>.............] - ETA: 2s - loss: 1.0556 - acc: 0.6232\n",
      " 95/156 [=================>............] - ETA: 2s - loss: 1.0547 - acc: 0.6235\n",
      " 97/156 [=================>............] - ETA: 2s - loss: 1.0548 - acc: 0.6233\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 2s - loss: 1.0553 - acc: 0.6233\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 2s - loss: 1.0569 - acc: 0.6228\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 1s - loss: 1.0584 - acc: 0.6227\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 1s - loss: 1.0595 - acc: 0.6221\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 1s - loss: 1.0580 - acc: 0.6225\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 1s - loss: 1.0599 - acc: 0.6216\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 1s - loss: 1.0589 - acc: 0.6219\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 1s - loss: 1.0580 - acc: 0.6222\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 1s - loss: 1.0582 - acc: 0.6226\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 1s - loss: 1.0569 - acc: 0.6227\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 1s - loss: 1.0559 - acc: 0.6233\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 1s - loss: 1.0563 - acc: 0.6228\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 1s - loss: 1.0560 - acc: 0.6232\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 1s - loss: 1.0570 - acc: 0.6227\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 1s - loss: 1.0566 - acc: 0.6229\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 0s - loss: 1.0566 - acc: 0.6225\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 0s - loss: 1.0568 - acc: 0.6223\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 0s - loss: 1.0549 - acc: 0.6231\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 0s - loss: 1.0554 - acc: 0.6229\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 0s - loss: 1.0551 - acc: 0.6231\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 0s - loss: 1.0544 - acc: 0.6232\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 0s - loss: 1.0538 - acc: 0.6231\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 0s - loss: 1.0531 - acc: 0.6235\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 0s - loss: 1.0526 - acc: 0.6237\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 0s - loss: 1.0524 - acc: 0.6242\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 0s - loss: 1.0515 - acc: 0.6247\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 0s - loss: 1.0500 - acc: 0.6253\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 0s - loss: 1.0494 - acc: 0.6253\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 1.0486 - acc: 0.6254\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 7s 43ms/step - loss: 1.0493 - acc: 0.6252 - val_loss: 1.1330 - val_acc: 0.5987\u001b[0m\n",
      "\u001b[34mEpoch 7/10\n",
      "\n",
      "  1/156 [..............................] - ETA: 5s - loss: 0.9563 - acc: 0.6680\n",
      "  3/156 [..............................] - ETA: 5s - loss: 0.9887 - acc: 0.6341\n",
      "  5/156 [..............................] - ETA: 5s - loss: 1.0093 - acc: 0.6352\n",
      "  7/156 [>.............................] - ETA: 5s - loss: 1.0118 - acc: 0.6295\n",
      "  9/156 [>.............................] - ETA: 5s - loss: 1.0412 - acc: 0.6241\n",
      " 11/156 [=>............................] - ETA: 5s - loss: 1.0381 - acc: 0.6275\n",
      " 13/156 [=>............................] - ETA: 5s - loss: 1.0350 - acc: 0.6292\n",
      " 15/156 [=>............................] - ETA: 5s - loss: 1.0371 - acc: 0.6279\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 5s - loss: 1.0340 - acc: 0.6291\n",
      " 19/156 [==>...........................] - ETA: 5s - loss: 1.0292 - acc: 0.6312\n",
      " 21/156 [===>..........................] - ETA: 4s - loss: 1.0348 - acc: 0.6300\n",
      " 23/156 [===>..........................] - ETA: 4s - loss: 1.0272 - acc: 0.6309\n",
      " 25/156 [===>..........................] - ETA: 4s - loss: 1.0193 - acc: 0.6327\n",
      " 27/156 [====>.........................] - ETA: 4s - loss: 1.0213 - acc: 0.6311\n",
      " 29/156 [====>.........................] - ETA: 4s - loss: 1.0233 - acc: 0.6307\n",
      " 31/156 [====>.........................] - ETA: 4s - loss: 1.0232 - acc: 0.6305\n",
      " 33/156 [=====>........................] - ETA: 4s - loss: 1.0215 - acc: 0.6315\n",
      " 35/156 [=====>........................] - ETA: 4s - loss: 1.0185 - acc: 0.6327\n",
      " 37/156 [======>.......................] - ETA: 4s - loss: 1.0128 - acc: 0.6356\n",
      " 39/156 [======>.......................] - ETA: 4s - loss: 1.0092 - acc: 0.6371\n",
      " 41/156 [======>.......................] - ETA: 4s - loss: 1.0086 - acc: 0.6382\n",
      " 43/156 [=======>......................] - ETA: 4s - loss: 1.0102 - acc: 0.6372\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 4s - loss: 1.0092 - acc: 0.6379\n",
      " 47/156 [========>.....................] - ETA: 3s - loss: 1.0078 - acc: 0.6383\n",
      " 49/156 [========>.....................] - ETA: 3s - loss: 1.0100 - acc: 0.6386\n",
      " 51/156 [========>.....................] - ETA: 3s - loss: 1.0105 - acc: 0.6383\n",
      " 53/156 [=========>....................] - ETA: 3s - loss: 1.0120 - acc: 0.6382\n",
      " 55/156 [=========>....................] - ETA: 3s - loss: 1.0105 - acc: 0.6385\n",
      " 57/156 [=========>....................] - ETA: 3s - loss: 1.0075 - acc: 0.6408\n",
      " 59/156 [==========>...................] - ETA: 3s - loss: 1.0061 - acc: 0.6414\n",
      " 61/156 [==========>...................] - ETA: 3s - loss: 1.0068 - acc: 0.6412\n",
      " 63/156 [===========>..................] - ETA: 3s - loss: 1.0059 - acc: 0.6415\n",
      " 65/156 [===========>..................] - ETA: 3s - loss: 1.0023 - acc: 0.6428\n",
      " 67/156 [===========>..................] - ETA: 3s - loss: 1.0007 - acc: 0.6422\n",
      " 69/156 [============>.................] - ETA: 3s - loss: 0.9997 - acc: 0.6430\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 3s - loss: 1.0006 - acc: 0.6425\n",
      " 73/156 [=============>................] - ETA: 3s - loss: 0.9980 - acc: 0.6436\n",
      " 75/156 [=============>................] - ETA: 2s - loss: 0.9961 - acc: 0.6441\n",
      " 77/156 [=============>................] - ETA: 2s - loss: 0.9946 - acc: 0.6441\n",
      " 79/156 [==============>...............] - ETA: 2s - loss: 0.9951 - acc: 0.6444\n",
      " 81/156 [==============>...............] - ETA: 2s - loss: 0.9951 - acc: 0.6443\n",
      " 83/156 [==============>...............] - ETA: 2s - loss: 0.9949 - acc: 0.6443\n",
      " 85/156 [===============>..............] - ETA: 2s - loss: 0.9941 - acc: 0.6449\n",
      " 87/156 [===============>..............] - ETA: 2s - loss: 0.9925 - acc: 0.6455\n",
      " 89/156 [================>.............] - ETA: 2s - loss: 0.9907 - acc: 0.6462\n",
      " 91/156 [================>.............] - ETA: 2s - loss: 0.9882 - acc: 0.6465\n",
      " 93/156 [================>.............] - ETA: 2s - loss: 0.9876 - acc: 0.6466\n",
      " 95/156 [=================>............] - ETA: 2s - loss: 0.9877 - acc: 0.6467\n",
      " 97/156 [=================>............] - ETA: 2s - loss: 0.9904 - acc: 0.6459\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 2s - loss: 0.9905 - acc: 0.6460\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 2s - loss: 0.9893 - acc: 0.6464\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 1s - loss: 0.9883 - acc: 0.6468\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 1s - loss: 0.9874 - acc: 0.6473\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 1s - loss: 0.9888 - acc: 0.6473\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 1s - loss: 0.9888 - acc: 0.6472\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 1s - loss: 0.9886 - acc: 0.6471\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 1s - loss: 0.9881 - acc: 0.6476\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 1s - loss: 0.9895 - acc: 0.6468\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 1s - loss: 0.9898 - acc: 0.6466\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 1s - loss: 0.9890 - acc: 0.6467\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 1s - loss: 0.9889 - acc: 0.6467\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 1s - loss: 0.9884 - acc: 0.6470\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 1s - loss: 0.9875 - acc: 0.6472\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 1s - loss: 0.9872 - acc: 0.6474\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 0s - loss: 0.9866 - acc: 0.6476\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 0s - loss: 0.9869 - acc: 0.6478\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 0s - loss: 0.9860 - acc: 0.6484\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 0s - loss: 0.9859 - acc: 0.6486\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 0s - loss: 0.9871 - acc: 0.6482\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 0s - loss: 0.9862 - acc: 0.6484\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 0s - loss: 0.9861 - acc: 0.6484\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 0s - loss: 0.9860 - acc: 0.6482\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 0s - loss: 0.9864 - acc: 0.6482\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 0s - loss: 0.9867 - acc: 0.6485\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 0s - loss: 0.9856 - acc: 0.6490\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 0s - loss: 0.9851 - acc: 0.6490\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 0s - loss: 0.9841 - acc: 0.6492\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 0.9836 - acc: 0.6495\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 7s 43ms/step - loss: 0.9844 - acc: 0.6493 - val_loss: 0.8590 - val_acc: 0.6908\u001b[0m\n",
      "\u001b[34mEpoch 8/10\n",
      "\n",
      "  1/156 [..............................] - ETA: 5s - loss: 0.9258 - acc: 0.6992\n",
      "  3/156 [..............................] - ETA: 5s - loss: 1.0392 - acc: 0.6367\n",
      "  5/156 [..............................] - ETA: 5s - loss: 0.9825 - acc: 0.6562\n",
      "  7/156 [>.............................] - ETA: 5s - loss: 0.9841 - acc: 0.6518\n",
      "  9/156 [>.............................] - ETA: 5s - loss: 0.9783 - acc: 0.6580\n",
      " 11/156 [=>............................] - ETA: 5s - loss: 0.9734 - acc: 0.6594\n",
      " 13/156 [=>............................] - ETA: 5s - loss: 0.9676 - acc: 0.6611\n",
      " 15/156 [=>............................] - ETA: 5s - loss: 0.9581 - acc: 0.6635\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 5s - loss: 0.9597 - acc: 0.6625\n",
      " 19/156 [==>...........................] - ETA: 4s - loss: 0.9663 - acc: 0.6585\n",
      " 21/156 [===>..........................] - ETA: 4s - loss: 0.9593 - acc: 0.6618\n",
      " 23/156 [===>..........................] - ETA: 4s - loss: 0.9656 - acc: 0.6610\n",
      " 25/156 [===>..........................] - ETA: 4s - loss: 0.9680 - acc: 0.6608\n",
      " 27/156 [====>.........................] - ETA: 4s - loss: 0.9590 - acc: 0.6632\n",
      " 29/156 [====>.........................] - ETA: 4s - loss: 0.9627 - acc: 0.6626\n",
      " 31/156 [====>.........................] - ETA: 4s - loss: 0.9616 - acc: 0.6626\n",
      " 33/156 [=====>........................] - ETA: 4s - loss: 0.9586 - acc: 0.6631\n",
      " 35/156 [=====>........................] - ETA: 4s - loss: 0.9623 - acc: 0.6610\n",
      " 37/156 [======>.......................] - ETA: 4s - loss: 0.9579 - acc: 0.6627\n",
      " 39/156 [======>.......................] - ETA: 4s - loss: 0.9529 - acc: 0.6646\n",
      " 41/156 [======>.......................] - ETA: 4s - loss: 0.9500 - acc: 0.6657\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 4s - loss: 0.9520 - acc: 0.6652\n",
      " 45/156 [=======>......................] - ETA: 4s - loss: 0.9514 - acc: 0.6654\n",
      " 47/156 [========>.....................] - ETA: 4s - loss: 0.9524 - acc: 0.6653\n",
      " 49/156 [========>.....................] - ETA: 3s - loss: 0.9486 - acc: 0.6656\n",
      " 51/156 [========>.....................] - ETA: 3s - loss: 0.9491 - acc: 0.6654\n",
      " 53/156 [=========>....................] - ETA: 3s - loss: 0.9460 - acc: 0.6663\n",
      " 55/156 [=========>....................] - ETA: 3s - loss: 0.9461 - acc: 0.6676\n",
      " 57/156 [=========>....................] - ETA: 3s - loss: 0.9469 - acc: 0.6672\n",
      " 59/156 [==========>...................] - ETA: 3s - loss: 0.9470 - acc: 0.6676\n",
      " 61/156 [==========>...................] - ETA: 3s - loss: 0.9463 - acc: 0.6683\n",
      " 63/156 [===========>..................] - ETA: 3s - loss: 0.9443 - acc: 0.6682\n",
      " 65/156 [===========>..................] - ETA: 3s - loss: 0.9447 - acc: 0.6686\n",
      " 67/156 [===========>..................] - ETA: 3s - loss: 0.9433 - acc: 0.6690\n",
      " 69/156 [============>.................] - ETA: 3s - loss: 0.9429 - acc: 0.6692\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 3s - loss: 0.9414 - acc: 0.6703\n",
      " 73/156 [=============>................] - ETA: 3s - loss: 0.9399 - acc: 0.6706\n",
      " 75/156 [=============>................] - ETA: 2s - loss: 0.9385 - acc: 0.6704\n",
      " 77/156 [=============>................] - ETA: 2s - loss: 0.9392 - acc: 0.6700\n",
      " 79/156 [==============>...............] - ETA: 2s - loss: 0.9378 - acc: 0.6704\n",
      " 81/156 [==============>...............] - ETA: 2s - loss: 0.9372 - acc: 0.6706\n",
      " 83/156 [==============>...............] - ETA: 2s - loss: 0.9379 - acc: 0.6701\n",
      " 85/156 [===============>..............] - ETA: 2s - loss: 0.9385 - acc: 0.6695\n",
      " 87/156 [===============>..............] - ETA: 2s - loss: 0.9393 - acc: 0.6692\n",
      " 89/156 [================>.............] - ETA: 2s - loss: 0.9396 - acc: 0.6698\n",
      " 91/156 [================>.............] - ETA: 2s - loss: 0.9385 - acc: 0.6707\n",
      " 93/156 [================>.............] - ETA: 2s - loss: 0.9385 - acc: 0.6711\n",
      " 95/156 [=================>............] - ETA: 2s - loss: 0.9388 - acc: 0.6712\n",
      " 97/156 [=================>............] - ETA: 2s - loss: 0.9391 - acc: 0.6712\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 2s - loss: 0.9394 - acc: 0.6710\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 2s - loss: 0.9401 - acc: 0.6709\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 1s - loss: 0.9394 - acc: 0.6710\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 1s - loss: 0.9400 - acc: 0.6706\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 1s - loss: 0.9401 - acc: 0.6709\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 1s - loss: 0.9394 - acc: 0.6710\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 1s - loss: 0.9390 - acc: 0.6710\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 1s - loss: 0.9383 - acc: 0.6716\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 1s - loss: 0.9386 - acc: 0.6713\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 1s - loss: 0.9376 - acc: 0.6715\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 1s - loss: 0.9384 - acc: 0.6712\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 1s - loss: 0.9384 - acc: 0.6709\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 1s - loss: 0.9376 - acc: 0.6712\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 1s - loss: 0.9365 - acc: 0.6713\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 1s - loss: 0.9361 - acc: 0.6711\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 0s - loss: 0.9353 - acc: 0.6715\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 0s - loss: 0.9362 - acc: 0.6716\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 0s - loss: 0.9364 - acc: 0.6713\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 0s - loss: 0.9357 - acc: 0.6720\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 0s - loss: 0.9351 - acc: 0.6720\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 0s - loss: 0.9347 - acc: 0.6722\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 0s - loss: 0.9343 - acc: 0.6726\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 0s - loss: 0.9344 - acc: 0.6728\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 0s - loss: 0.9342 - acc: 0.6728\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 0s - loss: 0.9338 - acc: 0.6726\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 0s - loss: 0.9333 - acc: 0.6729\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 0s - loss: 0.9329 - acc: 0.6730\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 0s - loss: 0.9319 - acc: 0.6736\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 0.9318 - acc: 0.6735\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 7s 43ms/step - loss: 0.9315 - acc: 0.6735 - val_loss: 0.8568 - val_acc: 0.6905\u001b[0m\n",
      "\u001b[34mEpoch 9/10\n",
      "\n",
      "  1/156 [..............................] - ETA: 5s - loss: 0.9682 - acc: 0.6367\n",
      "  3/156 [..............................] - ETA: 5s - loss: 0.9478 - acc: 0.6549\n",
      "  5/156 [..............................] - ETA: 5s - loss: 0.9378 - acc: 0.6641\n",
      "  7/156 [>.............................] - ETA: 5s - loss: 0.9465 - acc: 0.6557\n",
      "  9/156 [>.............................] - ETA: 5s - loss: 0.9342 - acc: 0.6641\n",
      " 11/156 [=>............................] - ETA: 5s - loss: 0.9341 - acc: 0.6665\n",
      " 13/156 [=>............................] - ETA: 5s - loss: 0.9310 - acc: 0.6701\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 5s - loss: 0.9260 - acc: 0.6721\n",
      " 17/156 [==>...........................] - ETA: 5s - loss: 0.9281 - acc: 0.6721\n",
      " 19/156 [==>...........................] - ETA: 4s - loss: 0.9294 - acc: 0.6713\n",
      " 21/156 [===>..........................] - ETA: 4s - loss: 0.9280 - acc: 0.6719\n",
      " 23/156 [===>..........................] - ETA: 4s - loss: 0.9203 - acc: 0.6758\n",
      " 25/156 [===>..........................] - ETA: 4s - loss: 0.9205 - acc: 0.6763\n",
      " 27/156 [====>.........................] - ETA: 4s - loss: 0.9208 - acc: 0.6759\n",
      " 29/156 [====>.........................] - ETA: 4s - loss: 0.9207 - acc: 0.6752\n",
      " 31/156 [====>.........................] - ETA: 4s - loss: 0.9197 - acc: 0.6768\n",
      " 33/156 [=====>........................] - ETA: 4s - loss: 0.9179 - acc: 0.6779\n",
      " 35/156 [=====>........................] - ETA: 4s - loss: 0.9180 - acc: 0.6778\n",
      " 37/156 [======>.......................] - ETA: 4s - loss: 0.9181 - acc: 0.6777\n",
      " 39/156 [======>.......................] - ETA: 4s - loss: 0.9167 - acc: 0.6785\n",
      " 41/156 [======>.......................] - ETA: 4s - loss: 0.9134 - acc: 0.6793\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 4s - loss: 0.9122 - acc: 0.6802\n",
      " 45/156 [=======>......................] - ETA: 4s - loss: 0.9129 - acc: 0.6807\n",
      " 47/156 [========>.....................] - ETA: 3s - loss: 0.9116 - acc: 0.6813\n",
      " 49/156 [========>.....................] - ETA: 3s - loss: 0.9082 - acc: 0.6814\n",
      " 51/156 [========>.....................] - ETA: 3s - loss: 0.9077 - acc: 0.6818\n",
      " 53/156 [=========>....................] - ETA: 3s - loss: 0.9082 - acc: 0.6815\n",
      " 55/156 [=========>....................] - ETA: 3s - loss: 0.9075 - acc: 0.6817\n",
      " 57/156 [=========>....................] - ETA: 3s - loss: 0.9072 - acc: 0.6821\n",
      " 59/156 [==========>...................] - ETA: 3s - loss: 0.9103 - acc: 0.6811\n",
      " 61/156 [==========>...................] - ETA: 3s - loss: 0.9087 - acc: 0.6810\n",
      " 63/156 [===========>..................] - ETA: 3s - loss: 0.9070 - acc: 0.6819\n",
      " 65/156 [===========>..................] - ETA: 3s - loss: 0.9062 - acc: 0.6817\n",
      " 67/156 [===========>..................] - ETA: 3s - loss: 0.9041 - acc: 0.6825\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 3s - loss: 0.9031 - acc: 0.6831\n",
      " 71/156 [============>.................] - ETA: 3s - loss: 0.9032 - acc: 0.6831\n",
      " 73/156 [=============>................] - ETA: 3s - loss: 0.9024 - acc: 0.6835\n",
      " 75/156 [=============>................] - ETA: 2s - loss: 0.9022 - acc: 0.6834\n",
      " 77/156 [=============>................] - ETA: 2s - loss: 0.9037 - acc: 0.6825\n",
      " 79/156 [==============>...............] - ETA: 2s - loss: 0.9052 - acc: 0.6822\n",
      " 81/156 [==============>...............] - ETA: 2s - loss: 0.9039 - acc: 0.6827\n",
      " 83/156 [==============>...............] - ETA: 2s - loss: 0.9035 - acc: 0.6831\n",
      " 85/156 [===============>..............] - ETA: 2s - loss: 0.9036 - acc: 0.6831\n",
      " 87/156 [===============>..............] - ETA: 2s - loss: 0.9031 - acc: 0.6832\n",
      " 89/156 [================>.............] - ETA: 2s - loss: 0.9039 - acc: 0.6836\n",
      " 91/156 [================>.............] - ETA: 2s - loss: 0.9031 - acc: 0.6833\n",
      " 93/156 [================>.............] - ETA: 2s - loss: 0.9011 - acc: 0.6838\n",
      " 95/156 [=================>............] - ETA: 2s - loss: 0.9002 - acc: 0.6838\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 2s - loss: 0.8995 - acc: 0.6839\n",
      " 99/156 [==================>...........] - ETA: 2s - loss: 0.8975 - acc: 0.6844\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 2s - loss: 0.8980 - acc: 0.6837\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 1s - loss: 0.8987 - acc: 0.6837\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 1s - loss: 0.8994 - acc: 0.6831\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 1s - loss: 0.8997 - acc: 0.6833\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 1s - loss: 0.8983 - acc: 0.6835\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 1s - loss: 0.8990 - acc: 0.6833\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 1s - loss: 0.8972 - acc: 0.6842\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 1s - loss: 0.8977 - acc: 0.6841\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 1s - loss: 0.8984 - acc: 0.6839\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 1s - loss: 0.8984 - acc: 0.6840\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 1s - loss: 0.8986 - acc: 0.6839\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 1s - loss: 0.8990 - acc: 0.6840\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 1s - loss: 0.8991 - acc: 0.6839\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 1s - loss: 0.8990 - acc: 0.6838\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 0s - loss: 0.8986 - acc: 0.6841\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 0s - loss: 0.8984 - acc: 0.6842\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 0s - loss: 0.8984 - acc: 0.6844\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 0s - loss: 0.8982 - acc: 0.6845\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 0s - loss: 0.8986 - acc: 0.6845\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 0s - loss: 0.8986 - acc: 0.6847\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 0s - loss: 0.8978 - acc: 0.6850\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 0s - loss: 0.8974 - acc: 0.6852\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 0s - loss: 0.8971 - acc: 0.6852\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 0s - loss: 0.8969 - acc: 0.6854\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 0s - loss: 0.8974 - acc: 0.6856\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 0s - loss: 0.8973 - acc: 0.6856\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 0s - loss: 0.8966 - acc: 0.6856\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 0.8958 - acc: 0.6860\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 7s 43ms/step - loss: 0.8954 - acc: 0.6860 - val_loss: 1.1931 - val_acc: 0.5921\u001b[0m\n",
      "\u001b[34mEpoch 10/10\n",
      "\n",
      "  1/156 [..............................] - ETA: 5s - loss: 0.9459 - acc: 0.6719\n",
      "  3/156 [..............................] - ETA: 5s - loss: 0.8713 - acc: 0.6849\n",
      "  5/156 [..............................] - ETA: 5s - loss: 0.8485 - acc: 0.6961\n",
      "  7/156 [>.............................] - ETA: 5s - loss: 0.8624 - acc: 0.6920\n",
      "  9/156 [>.............................] - ETA: 5s - loss: 0.8885 - acc: 0.6923\n",
      " 11/156 [=>............................] - ETA: 5s - loss: 0.8895 - acc: 0.6886\n",
      " 13/156 [=>............................] - ETA: 5s - loss: 0.8913 - acc: 0.6863\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 5s - loss: 0.8922 - acc: 0.6875\n",
      " 17/156 [==>...........................] - ETA: 5s - loss: 0.8852 - acc: 0.6909\n",
      " 19/156 [==>...........................] - ETA: 4s - loss: 0.8817 - acc: 0.6916\n",
      " 21/156 [===>..........................] - ETA: 4s - loss: 0.8768 - acc: 0.6938\n",
      " 23/156 [===>..........................] - ETA: 4s - loss: 0.8775 - acc: 0.6960\n",
      " 25/156 [===>..........................] - ETA: 4s - loss: 0.8786 - acc: 0.6950\n",
      " 27/156 [====>.........................] - ETA: 4s - loss: 0.8726 - acc: 0.6963\n",
      " 29/156 [====>.........................] - ETA: 4s - loss: 0.8731 - acc: 0.6959\n",
      " 31/156 [====>.........................] - ETA: 4s - loss: 0.8729 - acc: 0.6954\n",
      " 33/156 [=====>........................] - ETA: 4s - loss: 0.8789 - acc: 0.6920\n",
      " 35/156 [=====>........................] - ETA: 4s - loss: 0.8767 - acc: 0.6936\n",
      " 37/156 [======>.......................] - ETA: 4s - loss: 0.8774 - acc: 0.6919\n",
      " 39/156 [======>.......................] - ETA: 4s - loss: 0.8773 - acc: 0.6921\n",
      " 41/156 [======>.......................] - ETA: 4s - loss: 0.8751 - acc: 0.6931\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 4s - loss: 0.8726 - acc: 0.6934\n",
      " 45/156 [=======>......................] - ETA: 4s - loss: 0.8741 - acc: 0.6921\n",
      " 47/156 [========>.....................] - ETA: 3s - loss: 0.8723 - acc: 0.6921\n",
      " 49/156 [========>.....................] - ETA: 3s - loss: 0.8694 - acc: 0.6932\n",
      " 51/156 [========>.....................] - ETA: 3s - loss: 0.8684 - acc: 0.6940\n",
      " 53/156 [=========>....................] - ETA: 3s - loss: 0.8735 - acc: 0.6928\n",
      " 55/156 [=========>....................] - ETA: 3s - loss: 0.8707 - acc: 0.6947\n",
      " 57/156 [=========>....................] - ETA: 3s - loss: 0.8682 - acc: 0.6948\n",
      " 59/156 [==========>...................] - ETA: 3s - loss: 0.8660 - acc: 0.6957\n",
      " 61/156 [==========>...................] - ETA: 3s - loss: 0.8686 - acc: 0.6945\n",
      " 63/156 [===========>..................] - ETA: 3s - loss: 0.8672 - acc: 0.6957\n",
      " 65/156 [===========>..................] - ETA: 3s - loss: 0.8659 - acc: 0.6954\n",
      " 67/156 [===========>..................] - ETA: 3s - loss: 0.8661 - acc: 0.6953\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 3s - loss: 0.8652 - acc: 0.6957\n",
      " 71/156 [============>.................] - ETA: 3s - loss: 0.8658 - acc: 0.6959\n",
      " 73/156 [=============>................] - ETA: 3s - loss: 0.8659 - acc: 0.6958\n",
      " 75/156 [=============>................] - ETA: 2s - loss: 0.8670 - acc: 0.6963\n",
      " 77/156 [=============>................] - ETA: 2s - loss: 0.8679 - acc: 0.6957\n",
      " 81/156 [==============>...............] - ETA: 2s - loss: 0.8673 - acc: 0.6959\n",
      " 85/156 [===============>..............] - ETA: 2s - loss: 0.8681 - acc: 0.6953\n",
      " 89/156 [================>.............] - ETA: 2s - loss: 0.8655 - acc: 0.6960\n",
      " 93/156 [================>.............] - ETA: 2s - loss: 0.8678 - acc: 0.6957\n",
      " 97/156 [=================>............] - ETA: 1s - loss: 0.8668 - acc: 0.6955\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 1s - loss: 0.8661 - acc: 0.6958\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 1s - loss: 0.8663 - acc: 0.6954\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 1s - loss: 0.8672 - acc: 0.6953\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 1s - loss: 0.8660 - acc: 0.6955\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 1s - loss: 0.8678 - acc: 0.6949\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 0s - loss: 0.8678 - acc: 0.6949\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 0s - loss: 0.8687 - acc: 0.6949\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 0s - loss: 0.8709 - acc: 0.6941\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 0s - loss: 0.8703 - acc: 0.6945\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 0s - loss: 0.8705 - acc: 0.6941\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 0s - loss: 0.8710 - acc: 0.6938\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 0s - loss: 0.8707 - acc: 0.6942\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 0s - loss: 0.8700 - acc: 0.6944\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 0s - loss: 0.8687 - acc: 0.6951\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 5s 32ms/step - loss: 0.8681 - acc: 0.6954 - val_loss: 0.8986 - val_acc: 0.6783\u001b[0m\n",
      "\u001b[34mINFO:root:Test loss:0.9250883444761618\u001b[0m\n",
      "\u001b[34mINFO:root:Test accuracy:0.6753806089743589\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to save.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to save.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\u001b[0m\n",
      "\u001b[34mINFO:root:Model successfully saved at: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2020-05-05 19:29:06,135 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-05-05 19:29:15 Uploading - Uploading generated training model\n",
      "2020-05-05 19:29:15 Completed - Training job completed\n",
      "Training seconds: 151\n",
      "Billable seconds: 151\n"
     ]
    }
   ],
   "source": [
    "remote_inputs = {'train' : dataset_location+'/train', 'validation' : dataset_location+'/validation', 'eval' : dataset_location+'/eval'}\n",
    "estimator.fit(remote_inputs, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the job training metrics\n",
    "SageMaker used the regular expression configured above, to send the job metrics to CloudWatch metrics.\n",
    "You can now view the job metrics directly from the SageMaker console.  \n",
    "\n",
    "login to the [SageMaker console](https://console.aws.amazon.com/sagemaker/home) choose the latest training job, scroll down to the monitor section.  \n",
    "Using CloudWatch metrics, you can change the period and configure the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "CloudWatch metrics: [link](https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#metricsV2:query=%7B/aws/sagemaker/TrainingJobs,TrainingJobName%7D%20cifar10-tf-2020-05-05-19-24-30-359)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "After you choose a metric, change the period to 1 Minute (Graphed Metrics -> Period)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import Markdown\n",
    "\n",
    "link = 'https://console.aws.amazon.com/cloudwatch/home?region='+sagemaker_session.boto_region_name+'#metricsV2:query=%7B/aws/sagemaker/TrainingJobs,TrainingJobName%7D%20'+estimator.latest_training_job.job_name\n",
    "display(Markdown('CloudWatch metrics: [link]('+link+')'))\n",
    "display(Markdown('After you choose a metric, change the period to 1 Minute (Graphed Metrics -> Period)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on SageMaker with Pipe Mode input\n",
    "SageMaker Pipe Mode is a mechanism for providing S3 data to a training job via Linux fifos. Training programs can read from the fifo and get high-throughput data transfer from S3, without managing the S3 access in the program itself.\n",
    "Pipe Mode is covered in more detail in the SageMaker [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html#your-algorithms-training-algo-running-container-inputdataconfig)\n",
    "\n",
    "in out script, we enabled Pipe Mode using the following code:\n",
    "```python\n",
    "from sagemaker_tensorflow import PipeModeDataset\n",
    "dataset = PipeModeDataset(channel=channel_name, record_format='TFRecord')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "source_dir = os.path.join(os.getcwd(), 'source_dir')\n",
    "estimator_pipe = TensorFlow(base_job_name='pipe-cifar10-tf',\n",
    "                       entry_point='cifar10_keras_main.py',\n",
    "                       source_dir=source_dir,\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       train_instance_count=1, train_instance_type='ml.p3.2xlarge',\n",
    "                       tags = [{'Key' : 'Project', 'Value' : 'cifar10'},{'Key' : 'TensorBoard', 'Value' : 'pipe'}],\n",
    "                       metric_definitions=keras_metric_definition,\n",
    "                       input_mode='Pipe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we set ```wait=False``` if you want to see the output logs, change this to ```wait=True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = {'train' : dataset_location+'/train', 'validation' : dataset_location+'/validation', 'eval' : dataset_location+'/eval'}\n",
    "estimator_pipe.fit(remote_inputs, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed training with horovod\n",
    "Horovod is a distributed training framework based on MPI. Horovod is only available with TensorFlow version 1.12 or newer. You can find more details at Horovod README.\n",
    "\n",
    "To enable Horovod, we need to add the following code to our script:\n",
    "```python\n",
    "import horovod.keras as hvd\n",
    "hvd.init()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "K.set_session(tf.Session(config=config))\n",
    "```\n",
    "\n",
    "Add the following callbacks:\n",
    "```python\n",
    "hvd.callbacks.BroadcastGlobalVariablesCallback(0)\n",
    "hvd.callbacks.MetricAverageCallback()\n",
    "```\n",
    "\n",
    "Configure the optimizer:\n",
    "```python\n",
    "opt = Adam(lr=learning_rate * size, decay=weight_decay)\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "```\n",
    "Choose to save checkpoints and send TensorBoard logs only from the ```python hvd.rank() == 0``` instance\n",
    "\n",
    "To start a distributed training job with Horovod, configure the job distribution:\n",
    "```python\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': # Number of Horovod processes per host\n",
    "                        }\n",
    "                }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': 1\n",
    "                        }\n",
    "                }\n",
    "hyperparameters = {'epochs': 10, 'batch-size' : 256}\n",
    "\n",
    "source_dir = os.path.join(os.getcwd(), 'source_dir')\n",
    "estimator_dist = TensorFlow(base_job_name='dist-cifar10-tf',\n",
    "                       entry_point='cifar10_keras_main.py',\n",
    "                       source_dir=source_dir,\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       train_instance_count=2, train_instance_type='ml.p3.2xlarge',\n",
    "                       tags = [{'Key' : 'Project', 'Value' : 'cifar10'},{'Key' : 'TensorBoard', 'Value' : 'dist'}],\n",
    "                       metric_definitions=keras_metric_definition,\n",
    "                       distributions=distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we set ```wait=False``` if you want to see the output logs, change this to ```wait=True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = {'train' : dataset_location+'/train', 'validation' : dataset_location+'/validation', 'eval' : dataset_location+'/eval'}\n",
    "estimator_dist.fit(remote_inputs, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local TensorBoard command\n",
    "Using TensorBoard we can compare the jobs we ran. The following command prints the TensorBoard command.\n",
    "Run it in any environment where you have TensorBoard installed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_tensorboard_command.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install [TensorBoard](https://github.com/tensorflow/tensorboard) locally using `pip install tensorboard`.  \n",
    "To access an S3 log directory, configure the TensorBoard default region. You can do this by configuring an environment variable named AWS_REGION, and setting the value of the environment variable to the AWS region your training jobs run in.  \n",
    "For example, `export AWS_REGION = 'us-east-1'`\n",
    "\n",
    "You can access TensorBoard locally at http://localhost:6006\n",
    "\n",
    "Based on the TensorBoard metrics, we can see that:\n",
    "1. All jobs run for 10 epochs (0 - 9).\n",
    "2. File mode and Pipe mode runs for ~1 minute - Pipemode doesn't effect training performance.\n",
    "3. Distributed mode runs for 45 seconds.\n",
    "4. All of the training jobs resulted in similar validation accuracy.\n",
    "\n",
    "This example uses a small dataset (179 MB). For larger datasets, pipemode can significantly reduce training time because it does not copy the entire dataset into local memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model\n",
    "\n",
    "The deploy() method creates an endpoint that serves prediction requests in real-time.\n",
    "The model saves keras artifacts, to use TensorFlow serving for deployment, you'll need to save the artifacts in SavedModel format.\n",
    "\n",
    "We are using the solutions from the [deploy trained keras or tensorflow models using amazon sagemaker](https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker/) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some predictions\n",
    "To verify the that the endpoint functions properly, we generate random data in the correct shape and get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating fake prediction data\n",
    "import numpy as np\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "print(\"Predicted class is {}\".format(np.argmax(predictor.predict(data)['predictions'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating accuracy and create a confusion matrix based on the test dataset\n",
    "\n",
    "Our endpoint works as expected, we'll now use the test dataset for predictions and calculate our model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "def predict(data):\n",
    "    predictions = predictor.predict(data)['predictions']\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "predicted = []\n",
    "actual = []\n",
    "batches = 0\n",
    "for data in datagen.flow(x_test,y_test,batch_size=batch_size):\n",
    "    for i,prediction in enumerate(predict(data[0])):\n",
    "        predicted.append(np.argmax(prediction))\n",
    "        actual.append(data[1][i][0])\n",
    "    batches += 1\n",
    "    if batches >= len(x_test) / batch_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_pred=predicted,y_true=actual)\n",
    "display('Average accuracy: {}%'.format(round(accuracy*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_pred=predicted,y_true=actual)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sn.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(cm, annot=True,annot_kws={\"size\": 10})# font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this heatmap we can calculate the accuracy of each one of the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up\n",
    "To avoid incurring charges to your AWS account for the resources used in this tutorial you need to delete the SageMaker Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
