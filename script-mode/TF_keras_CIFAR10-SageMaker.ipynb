{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Host a Keras Sequential Model\n",
    "## Using Pipe Mode datasets and distributed training with Horovod\n",
    "This notebook shows how to train and host a Keras Sequential model on SageMaker. The model used for this notebook is a simple deep CNN that was extracted from [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is one of the most popular machine learning datasets. It consists of 60,000 32x32 images belonging to 10 different classes (6,000 images per class). Here are the classes in the dataset, as well as 10 random images from each:\n",
    "\n",
    "![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)\n",
    "\n",
    "In this tutorial, we will train a deep CNN to recognize these images.\n",
    "\n",
    "We'll compare trainig with file mode, pipe mode datasets and distributed training with Horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the CIFAR-10 dataset\n",
    "Downloading the test and training data takes around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/MLAI/script-mode\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Using cached wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9681 sha256=bed51e161a34013e340f106ddd671cc20f9f58c2491554c0886a5d5ad916515e\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/1d/93/c863ee832230df5cfc25ca497b3e88e0ee3ea9e44adc46ac62\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords_v1.x.py:34: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Generating data//train/train.tfrecords\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords_v1.x.py:68: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords_v1.x.py:57: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Generating data//validation/validation.tfrecords\n",
      "Generating data//eval/eval.tfrecords\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python generate_cifar10_tfrecords_v1.x.py --data-dir data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.TensorFlow estimator, running locally\n",
    "To test that the code will work in SageMaker, we'll first use SageMaker local mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "import subprocess\n",
    "instance_type = 'local'\n",
    "print(instance_type)\n",
    "if subprocess.call('nvidia-smi') == 0:\n",
    "    ## Set type to GPU if one is present\n",
    "    instance_type = 'local_gpu'\n",
    "    \n",
    "local_hyperparameters = {'epochs': 2, 'batch-size' : 64}\n",
    "\n",
    "source_dir = os.path.join(os.getcwd(), 'source_dir')\n",
    "estimator = TensorFlow(entry_point='cifar10_keras_main.py',\n",
    "                       source_dir=source_dir,\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=local_hyperparameters,\n",
    "                       train_instance_count=1, train_instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpiaba668c_algo-1-bs0ry_1 ... \n",
      "\u001b[1BAttaching to tmpiaba668c_algo-1-bs0ry_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m 2020-05-05 19:08:00,915 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m 2020-05-05 19:08:00,922 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m 2020-05-05 19:08:01,848 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m 2020-05-05 19:08:01,861 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m 2020-05-05 19:08:01,871 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"eval\": \"/opt/ml/input/data/eval\"\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"current_host\": \"algo-1-bs0ry\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"algo-1-bs0ry\"\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"epochs\": 2,\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"batch-size\": 64,\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"model_dir\": \"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/model\"\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"validation\": {\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"eval\": {\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"job_name\": \"sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"master_hostname\": \"algo-1-bs0ry\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"module_name\": \"cifar10_keras_main\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"num_cpus\": 16,\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"current_host\": \"algo-1-bs0ry\",\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m             \"algo-1-bs0ry\"\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m     \"user_entry_point\": \"cifar10_keras_main.py\"\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_HOSTS=[\"algo-1-bs0ry\"]\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_HPS={\"batch-size\":64,\"epochs\":2,\"model_dir\":\"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/model\"}\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_USER_ENTRY_POINT=cifar10_keras_main.py\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-bs0ry\",\"hosts\":[\"algo-1-bs0ry\"]}\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_CHANNELS=[\"eval\",\"train\",\"validation\"]\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_CURRENT_HOST=algo-1-bs0ry\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_MODULE_NAME=cifar10_keras_main\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_NUM_CPUS=16\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-bs0ry\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-bs0ry\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":2,\"model_dir\":\"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406\",\"log_level\":20,\"master_hostname\":\"algo-1-bs0ry\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_keras_main\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-bs0ry\",\"hosts\":[\"algo-1-bs0ry\"]},\"user_entry_point\":\"cifar10_keras_main.py\"}\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"2\",\"--model_dir\",\"s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/model\"]\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_CHANNEL_EVAL=/opt/ml/input/data/eval\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_HP_EPOCHS=2\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_HP_BATCH-SIZE=64\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/model\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m /usr/bin/python cifar10_keras_main.py --batch-size 64 --epochs 2 --model_dir s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/model\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m \n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m Using TensorFlow backend.\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:Writing TensorBoard logs to s3://sagemaker-us-east-1-079329190341/sagemaker-tensorflow-scriptmode-2020-05-05-19-07-53-406/model\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:Running with MPI=False\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:getting data\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:Running train in File mode\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:Running eval in File mode\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:Running validation in File mode\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:configuring model\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:Starting training\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m Train on 64 samples, validate on 64 samples\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m Epoch 1/2\n",
      "625/625 [==============================] - 47s 76ms/step - loss: 1.8107 - acc: 0.3334 - val_loss: 3.1090 - val_acc: 0.2123\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m Epoch 2/2\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 1.4147 - acc: 0.4834 - val_loss: 1.2245 - val_acc: 0.5441\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:Test loss:1.2422301711944432\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:Test accuracy:0.5390625\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:tensorflow:No assets to save.\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:tensorflow:No assets to save.\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:tensorflow:No assets to write.\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:tensorflow:No assets to write.\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m INFO:root:Model successfully saved at: /opt/ml/model\n",
      "\u001b[36malgo-1-bs0ry_1  |\u001b[0m 2020-05-05 19:09:46,070 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpiaba668c_algo-1-bs0ry_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "local_inputs = {'train' : 'file://'+os.getcwd()+'/data/train', \n",
    "                'validation' : 'file://'+os.getcwd()+'/data/validation', \n",
    "                'eval' : 'file://'+os.getcwd()+'/data/eval'}\n",
    "estimator.fit(local_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on SageMaker cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-cifar10-tf')\n",
    "display(dataset_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring metrics from the job logs\n",
    "SageMaker can get training metrics directly from the logs and send them to CloudWatch metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_metric_definition = [\n",
    "    {'Name': 'train:loss', 'Regex': '.*loss: ([0-9\\\\.]+) - acc: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'train:accuracy', 'Regex': '.*loss: [0-9\\\\.]+ - acc: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:accuracy', 'Regex': '.*step - loss: [0-9\\\\.]+ - acc: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_acc: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:loss', 'Regex': '.*step - loss: [0-9\\\\.]+ - acc: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_acc: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'sec/steps', 'Regex': '.* - \\d+s (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - acc: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_acc: [0-9\\\\.]+'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train image classification based on the cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 10, 'batch-size' : 256}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "source_dir = os.path.join(os.getcwd(), 'source_dir')\n",
    "estimator = TensorFlow(base_job_name='cifar10-tf',\n",
    "                       entry_point='cifar10_keras_main.py',\n",
    "                       source_dir=source_dir,\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       train_instance_count=1, train_instance_type='ml.p3.2xlarge',\n",
    "                       tags = [{'Key' : 'Project', 'Value' : 'cifar10'},{'Key' : 'TensorBoard', 'Value' : 'file'}],\n",
    "                       metric_definitions=keras_metric_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = {'train' : dataset_location+'/train', 'validation' : dataset_location+'/validation', 'eval' : dataset_location+'/eval'}\n",
    "estimator.fit(remote_inputs, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the job training metrics\n",
    "SageMaker used the regular expression configured above, to send the job metrics to CloudWatch metrics.\n",
    "You can now view the job metrics directly from the SageMaker console.  \n",
    "\n",
    "login to the [SageMaker console](https://console.aws.amazon.com/sagemaker/home) choose the latest training job, scroll down to the monitor section.  \n",
    "Using CloudWatch metrics, you can change the period and configure the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown\n",
    "\n",
    "link = 'https://console.aws.amazon.com/cloudwatch/home?region='+sagemaker_session.boto_region_name+'#metricsV2:query=%7B/aws/sagemaker/TrainingJobs,TrainingJobName%7D%20'+estimator.latest_training_job.job_name\n",
    "display(Markdown('CloudWatch metrics: [link]('+link+')'))\n",
    "display(Markdown('After you choose a metric, change the period to 1 Minute (Graphed Metrics -> Period)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on SageMaker with Pipe Mode input\n",
    "SageMaker Pipe Mode is a mechanism for providing S3 data to a training job via Linux fifos. Training programs can read from the fifo and get high-throughput data transfer from S3, without managing the S3 access in the program itself.\n",
    "Pipe Mode is covered in more detail in the SageMaker [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html#your-algorithms-training-algo-running-container-inputdataconfig)\n",
    "\n",
    "in out script, we enabled Pipe Mode using the following code:\n",
    "```python\n",
    "from sagemaker_tensorflow import PipeModeDataset\n",
    "dataset = PipeModeDataset(channel=channel_name, record_format='TFRecord')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "source_dir = os.path.join(os.getcwd(), 'source_dir')\n",
    "estimator_pipe = TensorFlow(base_job_name='pipe-cifar10-tf',\n",
    "                       entry_point='cifar10_keras_main.py',\n",
    "                       source_dir=source_dir,\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       train_instance_count=1, train_instance_type='ml.p3.2xlarge',\n",
    "                       tags = [{'Key' : 'Project', 'Value' : 'cifar10'},{'Key' : 'TensorBoard', 'Value' : 'pipe'}],\n",
    "                       metric_definitions=keras_metric_definition,\n",
    "                       input_mode='Pipe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we set ```wait=False``` if you want to see the output logs, change this to ```wait=True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = {'train' : dataset_location+'/train', 'validation' : dataset_location+'/validation', 'eval' : dataset_location+'/eval'}\n",
    "estimator_pipe.fit(remote_inputs, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed training with horovod\n",
    "Horovod is a distributed training framework based on MPI. Horovod is only available with TensorFlow version 1.12 or newer. You can find more details at Horovod README.\n",
    "\n",
    "To enable Horovod, we need to add the following code to our script:\n",
    "```python\n",
    "import horovod.keras as hvd\n",
    "hvd.init()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "K.set_session(tf.Session(config=config))\n",
    "```\n",
    "\n",
    "Add the following callbacks:\n",
    "```python\n",
    "hvd.callbacks.BroadcastGlobalVariablesCallback(0)\n",
    "hvd.callbacks.MetricAverageCallback()\n",
    "```\n",
    "\n",
    "Configure the optimizer:\n",
    "```python\n",
    "opt = Adam(lr=learning_rate * size, decay=weight_decay)\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "```\n",
    "Choose to save checkpoints and send TensorBoard logs only from the ```python hvd.rank() == 0``` instance\n",
    "\n",
    "To start a distributed training job with Horovod, configure the job distribution:\n",
    "```python\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': # Number of Horovod processes per host\n",
    "                        }\n",
    "                }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': 1\n",
    "                        }\n",
    "                }\n",
    "hyperparameters = {'epochs': 10, 'batch-size' : 256}\n",
    "\n",
    "source_dir = os.path.join(os.getcwd(), 'source_dir')\n",
    "estimator_dist = TensorFlow(base_job_name='dist-cifar10-tf',\n",
    "                       entry_point='cifar10_keras_main.py',\n",
    "                       source_dir=source_dir,\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       train_instance_count=2, train_instance_type='ml.p3.2xlarge',\n",
    "                       tags = [{'Key' : 'Project', 'Value' : 'cifar10'},{'Key' : 'TensorBoard', 'Value' : 'dist'}],\n",
    "                       metric_definitions=keras_metric_definition,\n",
    "                       distributions=distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we set ```wait=False``` if you want to see the output logs, change this to ```wait=True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_inputs = {'train' : dataset_location+'/train', 'validation' : dataset_location+'/validation', 'eval' : dataset_location+'/eval'}\n",
    "estimator_dist.fit(remote_inputs, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local TensorBoard command\n",
    "Using TensorBoard we can compare the jobs we ran. The following command prints the TensorBoard command.\n",
    "Run it in any environment where you have TensorBoard installed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_tensorboard_command.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install [TensorBoard](https://github.com/tensorflow/tensorboard) locally using `pip install tensorboard`.  \n",
    "To access an S3 log directory, configure the TensorBoard default region. You can do this by configuring an environment variable named AWS_REGION, and setting the value of the environment variable to the AWS region your training jobs run in.  \n",
    "For example, `export AWS_REGION = 'us-east-1'`\n",
    "\n",
    "You can access TensorBoard locally at http://localhost:6006\n",
    "\n",
    "Based on the TensorBoard metrics, we can see that:\n",
    "1. All jobs run for 10 epochs (0 - 9).\n",
    "2. File mode and Pipe mode runs for ~1 minute - Pipemode doesn't effect training performance.\n",
    "3. Distributed mode runs for 45 seconds.\n",
    "4. All of the training jobs resulted in similar validation accuracy.\n",
    "\n",
    "This example uses a small dataset (179 MB). For larger datasets, pipemode can significantly reduce training time because it does not copy the entire dataset into local memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model\n",
    "\n",
    "The deploy() method creates an endpoint that serves prediction requests in real-time.\n",
    "The model saves keras artifacts, to use TensorFlow serving for deployment, you'll need to save the artifacts in SavedModel format.\n",
    "\n",
    "We are using the solutions from the [deploy trained keras or tensorflow models using amazon sagemaker](https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker/) blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some predictions\n",
    "To verify the that the endpoint functions properly, we generate random data in the correct shape and get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating fake prediction data\n",
    "import numpy as np\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "print(\"Predicted class is {}\".format(np.argmax(predictor.predict(data)['predictions'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating accuracy and create a confusion matrix based on the test dataset\n",
    "\n",
    "Our endpoint works as expected, we'll now use the test dataset for predictions and calculate our model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "def predict(data):\n",
    "    predictions = predictor.predict(data)['predictions']\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "predicted = []\n",
    "actual = []\n",
    "batches = 0\n",
    "for data in datagen.flow(x_test,y_test,batch_size=batch_size):\n",
    "    for i,prediction in enumerate(predict(data[0])):\n",
    "        predicted.append(np.argmax(prediction))\n",
    "        actual.append(data[1][i][0])\n",
    "    batches += 1\n",
    "    if batches >= len(x_test) / batch_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_pred=predicted,y_true=actual)\n",
    "display('Average accuracy: {}%'.format(round(accuracy*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_pred=predicted,y_true=actual)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sn.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(cm, annot=True,annot_kws={\"size\": 10})# font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this heatmap we can calculate the accuracy of each one of the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up\n",
    "To avoid incurring charges to your AWS account for the resources used in this tutorial you need to delete the SageMaker Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
